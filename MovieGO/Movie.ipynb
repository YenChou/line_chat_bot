{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "菜單設定檔\n",
    "\n",
    "    設定圖面大小、按鍵名與功能\n",
    "    \n",
    "'''\n",
    "menuRawData1=\"\"\"\n",
    "{\n",
    "  \"size\": {\n",
    "    \"width\": 2500,\n",
    "    \"height\": 1686\n",
    "  },\n",
    "  \"selected\": true,\n",
    "  \"name\": \"001_用戶入系統選擇\",\n",
    "  \"chatBarText\": \"查看更多資訊\",\n",
    "  \"areas\": [\n",
    "    {\n",
    "      \"bounds\": {\n",
    "        \"x\": 4,\n",
    "        \"y\": 8,\n",
    "        \"width\": 1271,\n",
    "        \"height\": 1665\n",
    "      },\n",
    "      \"action\": {\n",
    "        \"type\": \"message\",\n",
    "        \"text\": \"::text:: 我要精準預測\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"bounds\": {\n",
    "        \"x\": 1275,\n",
    "        \"y\": 4,\n",
    "        \"width\": 1225,\n",
    "        \"height\": 1661\n",
    "      },\n",
    "      \"action\": {\n",
    "        \"type\": \"message\",\n",
    "        \"text\": \"::text:: 我想看電影\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "menuRawData2=\"\"\"\n",
    "{\n",
    "  \"size\": {\n",
    "    \"width\": 2500,\n",
    "    \"height\": 1686\n",
    "  },\n",
    "  \"selected\": true,\n",
    "  \"name\": \"002_用戶預測選擇\",\n",
    "  \"chatBarText\": \"查看更多資訊\",\n",
    "  \"areas\": [\n",
    "    {\n",
    "      \"bounds\": {\n",
    "        \"x\": 0,\n",
    "        \"y\": 4,\n",
    "        \"width\": 1267,\n",
    "        \"height\": 835\n",
    "      },\n",
    "      \"action\": {\n",
    "        \"type\": \"message\",\n",
    "        \"text\": \"::text:: 我想看電影\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"bounds\": {\n",
    "        \"x\": 1305,\n",
    "        \"y\": 0,\n",
    "        \"width\": 1195,\n",
    "        \"height\": 835\n",
    "      },\n",
    "      \"action\": {\n",
    "        \"type\": \"message\",\n",
    "        \"text\": \"::text:: 我填錯了想重來~\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"bounds\": {\n",
    "        \"x\": 8,\n",
    "        \"y\": 869,\n",
    "        \"width\": 1263,\n",
    "        \"height\": 817\n",
    "      },\n",
    "      \"action\": {\n",
    "        \"type\": \"message\",\n",
    "        \"text\": \"::text:: 專人馬上為你服務\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"bounds\": {\n",
    "        \"x\": 1297,\n",
    "        \"y\": 869,\n",
    "        \"width\": 1203,\n",
    "        \"height\": 817\n",
    "      },\n",
    "      \"action\": {\n",
    "        \"type\": \"message\",\n",
    "        \"text\": \"::text:: 專人馬上為你服務\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "讀取安全檔案內的字串，以供後續程式碼調用\n",
    "\n",
    "'''\n",
    "import json\n",
    "secretFileContentJson=json.load(open(\"../line_secret_key\",'r'))\n",
    "\n",
    "print(secretFileContentJson.get(\"channel_access_token\"))\n",
    "print(secretFileContentJson.get(\"secret_key\"))\n",
    "print(secretFileContentJson.get(\"self_user_id\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "取的第一個菜單的設定檔\n",
    "將先前準備的菜單設定檔，以Post消息寄發給Line\n",
    "\n",
    "    設定Line的遠端位置\n",
    "    設定消息的基本安全憑證\n",
    "    寄發消息，並取得回應之Id\n",
    "    \n",
    "\n",
    "'''\n",
    "\n",
    "import requests\n",
    "\n",
    "menuJson=json.loads(menuRawData1)\n",
    "\n",
    "createMenuEndpoint = 'https://api.line.me/v2/bot/richmenu'\n",
    "createMenuRequestHeader={'Content-Type':'application/json','Authorization':'Bearer %s' % secretFileContentJson[\"channel_access_token\"]}\n",
    "\n",
    "#print(createMenuRequestHeader)\n",
    "\n",
    "lineCreateMenuResponse = requests.post(createMenuEndpoint,headers=createMenuRequestHeader,data=json.dumps(menuJson))\n",
    "\n",
    "print(lineCreateMenuResponse)\n",
    "print(lineCreateMenuResponse.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "FIRST\n",
    "將先前準備的菜單照片，以Post消息寄發給Line\n",
    "    取得上面設定檔的Id\n",
    "    設定Line的遠端位置\n",
    "    設定消息的基本安全憑證\n",
    "    上傳照片，並取得回傳成果\n",
    "\n",
    "'''\n",
    "\n",
    "# 取得菜單Id \n",
    "uploadRichMenuId=json.loads(lineCreateMenuResponse.text).get(\"richMenuId\")\n",
    "print(uploadRichMenuId)\n",
    "#'https://api.line.me/v2/bot/richmenu/{richMenuId}/content'\n",
    "\n",
    "# 設定Line的遠端位置\n",
    "uploadMenuEndpoint='https://api.line.me/v2/bot/richmenu/%s/content' % uploadRichMenuId\n",
    "print(uploadMenuEndpoint)\n",
    "\n",
    "# 設定消息的基本安全憑證\n",
    "uploadMenuRequestHeader={'Content-Type':'image/jpeg','Authorization':'Bearer %s' % secretFileContentJson[\"channel_access_token\"]}\n",
    "\n",
    "# 上傳照片\n",
    "uploadImageFile=open(\"../images/pic1_resized.jpg\",'rb')\n",
    "lineUploadMenuResponse=requests.post(uploadMenuEndpoint,headers=uploadMenuRequestHeader,data=uploadImageFile)\n",
    "\n",
    "print(lineUploadMenuResponse)\n",
    "print(lineUploadMenuResponse.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "取得第二個菜單的設定檔\n",
    "將先前準備的菜單設定檔，以Post消息寄發給Line\n",
    "\n",
    "    設定Line的遠端位置\n",
    "    設定消息的基本安全憑證\n",
    "    寄發消息，並取得回應之Id\n",
    "    \n",
    "\n",
    "'''\n",
    "\n",
    "import requests\n",
    "\n",
    "menuJson2=json.loads(menuRawData2)\n",
    "\n",
    "createMenuEndpoint = 'https://api.line.me/v2/bot/richmenu'\n",
    "createMenuRequestHeader2={'Content-Type':'application/json','Authorization':'Bearer %s' % secretFileContentJson[\"channel_access_token\"]}\n",
    "\n",
    "#print(createMenuRequestHeader)\n",
    "\n",
    "lineCreateMenuResponse2 = requests.post(createMenuEndpoint,headers=createMenuRequestHeader2,data=json.dumps(menuJson2))\n",
    "\n",
    "print(lineCreateMenuResponse2)\n",
    "print(lineCreateMenuResponse2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SECOND\n",
    "將先前準備的菜單照片，以Post消息寄發給Line\n",
    "    取得上面設定檔的Id\n",
    "    設定Line的遠端位置\n",
    "    設定消息的基本安全憑證\n",
    "    上傳照片，並取得回傳成果\n",
    "\n",
    "'''\n",
    "\n",
    "# 取得菜單Id \n",
    "uploadRichMenuId2=json.loads(lineCreateMenuResponse2.text).get(\"richMenuId\")\n",
    "print(uploadRichMenuId2)\n",
    "#'https://api.line.me/v2/bot/richmenu/{richMenuId}/content'\n",
    "\n",
    "# 設定Line的遠端位置\n",
    "uploadMenuEndpoint2='https://api.line.me/v2/bot/richmenu/%s/content' % uploadRichMenuId2\n",
    "print(uploadMenuEndpoint2)\n",
    "\n",
    "# 設定消息的基本安全憑證\n",
    "uploadMenuRequestHeader={'Content-Type':'image/jpeg','Authorization':'Bearer %s' % secretFileContentJson[\"channel_access_token\"]}\n",
    "\n",
    "# 上傳照片\n",
    "uploadImageFile2=open(\"../images/pic2_resized.jpg\",'rb')\n",
    "lineUploadMenuResponse2=requests.post(uploadMenuEndpoint2,headers=uploadMenuRequestHeader,data=uploadImageFile2)\n",
    "\n",
    "print(lineUploadMenuResponse2)\n",
    "print(lineUploadMenuResponse2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "將選單綁定到特定用戶身上\n",
    "    取出上面得到的菜單Id及用戶id\n",
    "    設定Line的遠端位置\n",
    "    設定消息的基本安全憑證\n",
    "    發送消息告知\n",
    "\n",
    "'''\n",
    "\n",
    "# https://api.line.me/v2/bot/user/{userId}/richmenu/{richMenuId}\n",
    "\n",
    "# 取得菜單id\n",
    "linkRichMenuId=json.loads(lineCreateMenuResponse.text).get(\"richMenuId\")\n",
    "\n",
    "# 將菜單id與用戶id組合成遠端位置\n",
    "linkMenuEndpoint='https://api.line.me/v2/bot/user/%s/richmenu/%s' % (secretFileContentJson[\"self_user_id\"], linkRichMenuId)\n",
    "print(linkMenuEndpoint)\n",
    "\n",
    "# 設定消息基本安全憑證\n",
    "linkMenuRequestHeader={'Content-Type':'image/jpeg','Authorization':'Bearer %s' % secretFileContentJson[\"channel_access_token\"]}\n",
    "\n",
    "# 發送消息\n",
    "lineLinkMenuResponse=requests.post(linkMenuEndpoint,headers=linkMenuRequestHeader)\n",
    "print(lineLinkMenuResponse)\n",
    "print(lineLinkMenuResponse.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'secretFileContentJson' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4dfa0ec66440>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 取出用戶id，設定Line的遠端位置\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0muserMenuEndpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'https://api.line.me/v2/bot/user/%s/richmenu'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msecretFileContentJson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"self_user_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserMenuEndpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'secretFileContentJson' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "檢視用戶目前所綁定的菜單\n",
    "    取出用戶id\n",
    "    設定Line的遠端位置\n",
    "    設定消息的基本安全憑證\n",
    "    發送消息告知\n",
    "\n",
    "'''\n",
    "\n",
    "#  https://api.line.me/v2/bot/user/{userId}/richmenu\n",
    "\n",
    "# 取出用戶id，設定Line的遠端位置\n",
    "userMenuEndpoint='https://api.line.me/v2/bot/user/%s/richmenu' % (secretFileContentJson[\"self_user_id\"])\n",
    "print(userMenuEndpoint)\n",
    "\n",
    "# 設定消息的基本安全憑證\n",
    "userMenuRequestHeader={'Authorization':'Bearer %s' % secretFileContentJson[\"channel_access_token\"]}\n",
    "\n",
    "# 發送消息告知\n",
    "lineUserMenuResponse=requests.get(userMenuEndpoint,headers=userMenuRequestHeader)\n",
    "print(lineUserMenuResponse)\n",
    "print(lineUserMenuResponse.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "啟用伺服器基本樣板\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 引用Web Server套件\n",
    "from flask import Flask, request, abort\n",
    "\n",
    "# 從linebot 套件包裡引用 LineBotApi 與 WebhookHandler 類別\n",
    "from linebot import (\n",
    "    LineBotApi, WebhookHandler\n",
    ")\n",
    "\n",
    "# 引用無效簽章錯誤\n",
    "from linebot.exceptions import (\n",
    "    InvalidSignatureError\n",
    ")\n",
    "\n",
    "# 載入json處理套件\n",
    "import json\n",
    "\n",
    "# 載入基礎設定檔\n",
    "secretFileContentJson=json.load(open(\"../line_secret_key\",'r'))\n",
    "server_url=secretFileContentJson.get(\"server_url\")\n",
    "\n",
    "# 設定Server啟用細節\n",
    "app = Flask(__name__,static_url_path = \"/images\" , static_folder = \"../images/\")\n",
    "\n",
    "# 生成實體物件\n",
    "line_bot_api = LineBotApi(secretFileContentJson.get(\"channel_access_token\"))\n",
    "handler = WebhookHandler(secretFileContentJson.get(\"secret_key\"))\n",
    "\n",
    "# 啟動server對外接口，使Line能丟消息進來\n",
    "@app.route(\"/\", methods=['POST'])\n",
    "def callback():\n",
    "    # get X-Line-Signature header value\n",
    "    signature = request.headers['X-Line-Signature']\n",
    "\n",
    "    # get request body as text\n",
    "    body = request.get_data(as_text=True)\n",
    "    app.logger.info(\"Request body: \" + body)\n",
    "\n",
    "    # handle webhook body\n",
    "    try:\n",
    "        handler.handle(body, signature)\n",
    "    except InvalidSignatureError:\n",
    "        abort(400)\n",
    "\n",
    "    return 'OK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "製作文字與圖片的教學訊息\n",
    "\n",
    "'''\n",
    "# 將消息模型，文字收取消息與文字寄發消息 引入\n",
    "from linebot.models import (\n",
    "    MessageEvent, TextMessage, TextSendMessage, ImageSendMessage\n",
    ")\n",
    "\n",
    "# 消息清單\n",
    "reply_message_list=[\n",
    "TextSendMessage(text=\"您好，我們是專業推薦電影的平台\"),\n",
    "TextSendMessage(text=\"我們平台分為兩個部分，可以為你不知道想要看什麼電影時，會根據你在平台填寫的興趣去為你推薦電影\\n 如果您是廠商，我們可以根據變數可以為你分析出您的電影票房\")\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "撰寫用戶關注時，我們要處理的商業邏輯\n",
    "\n",
    "1. 取得用戶個資，並存回伺服器\n",
    "2. 把先前製作好的自定義菜單，與用戶做綁定\n",
    "3. 回應用戶，歡迎用的文字消息與圖片消息\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# 載入Follow事件\n",
    "from linebot.models.events import (\n",
    "    FollowEvent\n",
    ")\n",
    "\n",
    "# 載入requests套件\n",
    "import requests\n",
    "\n",
    "\n",
    "# 告知handler，如果收到FollowEvent，則做下面的方法處理\n",
    "@handler.add(FollowEvent)\n",
    "def reply_text_and_get_user_profile(event):\n",
    "    \n",
    "    # 取出消息內User的資料\n",
    "    user_profile = line_bot_api.get_profile(event.source.user_id)\n",
    "        \n",
    "     # 將用戶資訊存在檔案內\n",
    "    with open(\"../users.txt\", \"a\") as myfile:\n",
    "        myfile.write(json.dumps(vars(user_profile),sort_keys=True))\n",
    "        myfile.write('\\r\\n')\n",
    "        \n",
    "        \n",
    "    # 將菜單綁定在用戶身上\n",
    "    linkRichMenuId=secretFileContentJson.get(\"rich_menu_id\")\n",
    "    linkMenuEndpoint='https://api.line.me/v2/bot/user/%s/richmenu/%s' % (event.source.user_id, linkRichMenuId)\n",
    "    linkMenuRequestHeader={'Content-Type':'image/jpeg','Authorization':'Bearer %s' % secretFileContentJson[\"channel_access_token\"]}\n",
    "    lineLinkMenuResponse=requests.post(linkMenuEndpoint,headers=linkMenuRequestHeader)\n",
    "    \n",
    "    # 回覆文字消息與圖片消息\n",
    "    line_bot_api.reply_message(\n",
    "        event.reply_token,\n",
    "        reply_message_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# %load ../linebot_deployment-master/linebot_model.py\n",
    "\"\"\"\n",
    "Created on Fri Jul 12 17:21:16 2019\n",
    "\n",
    "@author: Big data\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Jul  7 12:56:10 2019\n",
    "\n",
    "@author: Big data\n",
    "\"\"\"  \n",
    "import numpy as np\n",
    "from pytrends.request import TrendReq #API\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from xgboost import plot_importance\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "t={\"movie_name\":\"herry\",\"Runtime\":\"101min\",\"budget_in_USD\":1400000,\"Production\":\"aaa\",\"imdbVotes\":0.5,\"IMDBscore\":0.6,\"TomatoesScore\":0.8,\"Metascore\":0.5,\"actor\":\"johney\",\n",
    "  \"Theater_num\":1000,\"movie_2_before\":50,\"movie_1_before\":50,\"movie_0_before\":50,\"Actor_2_before\":50,\"Actor_1_before\":50,\n",
    "  \"Actor_0_before\":50,\"Genre\":\"Action\",\"Language\":\"English\",\"Country\":\"USA\",\"classification\":\"R\",\"Released\":\"27 Feb 2019\"}\n",
    "def month(m):\n",
    "    mon = {\n",
    "        \"Jan\": 1, \"Feb\": 2, \"Mar\": 3, \"Apr\": 4, \"May\": 5, \"Jun\": 6,\n",
    "        \"Jul\": 7, \"Aug\": 8, \"Sep\": 9, \"Oct\": 10, \"Nov\": 11, \"Dec\": 12\n",
    "    }\n",
    "    return mon.get(m)\n",
    "\n",
    "def g_trend_movie(movie, release_date):\n",
    "    s_movie = movie\n",
    "    if \",\" in movie:  # Gooletrends不可使用\"，\" 分隔 所以將名稱有\"，\"的取代成空白\n",
    "        s_movie = movie.replace(\",\", \" \")\n",
    "    if \"：\" in movie:\n",
    "        s_movie = movie.split(\"：\")[0]\n",
    "\n",
    "    release_year = int(release_date.split(\" \")[-1])  # 取上映年分，還有前一年和後一年\n",
    "    release_mon = release_date.split(\" \")[1]\n",
    "    release_mon = month(release_mon)\n",
    "    release_day = int(release_date.split(\" \")[0])\n",
    "\n",
    "    front_year = int(release_year) - 1\n",
    "    next_year = int(release_year) + 1\n",
    "    timeframe = str(front_year) + \"-01-01 \" + str(next_year) + \"-12-31\"\n",
    "\n",
    "    pytrend = TrendReq(tz=360)\n",
    "    kw_list = [s_movie]\n",
    "    pytrend.build_payload(kw_list=kw_list, cat=34, timeframe=timeframe, geo=\"US\", gprop=\"\")  # 搜尋使用的參數,其中cat=34 為電影類別\n",
    "\n",
    "    moviedata = pytrend.interest_over_time().get(kw_list)\n",
    "    try:\n",
    "        moviedata.rename(columns={moviedata.columns[0]: \"Count\"}, inplace=True)\n",
    "        moviedata_list = json.loads(moviedata.to_json(orient='table'))['data']\n",
    "        if release_mon == 2:\n",
    "            start_mon = 12\n",
    "            start_year = release_year - 1\n",
    "        elif release_mon == 1:\n",
    "            start_mon = 11\n",
    "            start_year = release_year - 1\n",
    "        else:\n",
    "            start_mon = release_mon - 2\n",
    "            start_year = release_year\n",
    "        start_day = release_day\n",
    "        for l in moviedata_list:\n",
    "            tempdate = l[\"date\"][0:10]\n",
    "            l[\"date\"] = tempdate\n",
    "        node_day = 0\n",
    "        day_count = 0\n",
    "        node_count = 0\n",
    "        for l in moviedata_list:\n",
    "            year_gt = int(l[\"date\"].split(\"-\")[0])\n",
    "            mon_gt = int(l[\"date\"].split(\"-\")[1])\n",
    "            day_gt = int(l[\"date\"].split(\"-\")[-1])\n",
    "            if year_gt == start_year and mon_gt == start_mon:\n",
    "                if node_day < start_day:\n",
    "                    node_day = day_gt\n",
    "                    node_count = day_count\n",
    "            day_count += 1\n",
    "        # node_data= moviedata_list[node_count]\n",
    "\n",
    "        output_list = []\n",
    "        for i in range(17):\n",
    "            try:\n",
    "                # print(moviedata_list[node_count+i],i)\n",
    "                output_list.append(moviedata_list[node_count + i][\"Count\"])\n",
    "            except:\n",
    "                output_list.append(0)\n",
    "    except:\n",
    "        output_list = [0, 0, 0, 0, 0,\n",
    "                       0, 0, 0, 0, 0,\n",
    "                       0, 0, 0, 0, 0,\n",
    "                       0, 0]\n",
    "\n",
    "    output_df = pd.DataFrame([output_list])\n",
    "\n",
    "    j = 8\n",
    "    for i in range(0, 9, 1):\n",
    "        output_df = output_df.rename(columns={i: \"movie_\" + str(j) + \"_before\"})\n",
    "        j -= 1\n",
    "    j = 1\n",
    "    for i in range(9, 17, 1):\n",
    "        output_df = output_df.rename(columns={i: \"movie_\" + str(j) + \"_after\"})\n",
    "        j += 1\n",
    "    output_df = output_df.to_dict(orient='records')\n",
    "    return output_df\n",
    "\n",
    "def g_trend_actor(actor, release_date):\n",
    "    actor_alist = actor.split(\",\")\n",
    "\n",
    "    release_year = int(release_date.split(\" \")[-1])\n",
    "    release_mon = release_date.split(\" \")[1]\n",
    "    release_mon = month(release_mon)\n",
    "    release_day = int(release_date.split(\" \")[0])\n",
    "\n",
    "    timeframe = [\"2004-01-01 2007-12-31\", \"2008-01-01 2011-12-31\", \"2012-01-01 2015-12-31\", \"2016-01-01 2019-12-31\"]\n",
    "    output_total = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "    for actor in actor_alist:\n",
    "        actordata_list = []\n",
    "        for t in timeframe:\n",
    "            time.sleep(random.randint(3, 5))\n",
    "            # print(actor,t)\n",
    "            pytrend = TrendReq(tz=360)\n",
    "            kw_list = [actor]\n",
    "            pytrend.build_payload(kw_list=kw_list, cat=34, timeframe=t, geo=\"US\", gprop=\"\")  # 搜尋使用的參數,其中cat=34 為電影類別\n",
    "\n",
    "            actordata = pytrend.interest_over_time().get(kw_list)\n",
    "            try:\n",
    "                actordata.rename(columns={actordata.columns[0]: \"Count\"}, inplace=True)\n",
    "            except:\n",
    "                continue\n",
    "            temp_actordata_list = json.loads(actordata.to_json(orient='table'))['data']\n",
    "            actordata_list += temp_actordata_list\n",
    "\n",
    "        for l in actordata_list:\n",
    "            tempdate = l[\"date\"][0:10]\n",
    "            l[\"date\"] = tempdate\n",
    "\n",
    "        if release_mon == 2:\n",
    "            start_mon = 12\n",
    "            start_year = release_year - 1\n",
    "        elif release_mon == 1:\n",
    "            start_mon = 11\n",
    "            start_year = release_year - 1\n",
    "        else:\n",
    "            start_mon = release_mon - 2\n",
    "            start_year = release_year\n",
    "        start_day = release_day\n",
    "        node_day = 0\n",
    "        day_count = 0\n",
    "        node_count = 0\n",
    "        for l in actordata_list:\n",
    "            year_gt = int(l[\"date\"].split(\"-\")[0])\n",
    "            mon_gt = int(l[\"date\"].split(\"-\")[1])\n",
    "            day_gt = int(l[\"date\"].split(\"-\")[-1])\n",
    "            if year_gt == start_year and mon_gt == start_mon:\n",
    "                if node_day < start_day:\n",
    "                    node_day = day_gt\n",
    "                    node_count = day_count\n",
    "            day_count += 1\n",
    "        # print(actordata_list[node_count],\"rr\")\n",
    "\n",
    "        output_list = []\n",
    "        for i in range(17):\n",
    "            try:\n",
    "                # print(actordata_list[node_count+i],i)\n",
    "                output_list.append(actordata_list[node_count + i][\"Count\"])\n",
    "            except:\n",
    "                output_list.append(0)\n",
    "        output_list = np.array(output_list)\n",
    "\n",
    "        output_total = output_total + output_list\n",
    "    output_avg = output_total / len(actor_alist)\n",
    "    output_avg = pd.DataFrame([output_avg])\n",
    "    j = 8\n",
    "    for i in range(0, 9, 1):\n",
    "        output_avg = output_avg.rename(columns={i: \"Actor_\" + str(j) + \"_before\"})\n",
    "        j -= 1\n",
    "    j = 1\n",
    "    for i in range(9, 17, 1):\n",
    "        output_avg = output_avg.rename(columns={i: \"Actor_\" + str(j) + \"_after\"})\n",
    "        j += 1\n",
    "    output_avg = output_avg.to_dict(orient='records')\n",
    "    return output_avg\n",
    "\n",
    "def trends_for_line(m):\n",
    "    movie = m[\"movie_name\"]\n",
    "    release_date = m[\"Released\"]\n",
    "    actor = m[\"actor\"]\n",
    "    col_movie = g_trend_movie(movie, release_date)\n",
    "    col_actor = g_trend_actor(actor, release_date)\n",
    "    m = dict(m, **col_movie[0])\n",
    "    m = dict(m, **col_actor[0])\n",
    "\n",
    "    return m\n",
    "\n",
    "def model_yn(movielist):\n",
    "    \n",
    "    movielist['release_date_USA']=movielist['Released']\n",
    "    \n",
    "\n",
    "    want_keys={\n",
    "            'classification', 'Runtime', 'budget_in_USD', \n",
    "           'release_date_USA', 'Genre', 'imdbVotes', 'IMDBscore', 'TomatoesScore',\n",
    "           'Metascore', 'Theater_num', 'movie_2_before',\n",
    "           'movie_1_before', 'movie_0_before', 'Actor_2_before',\n",
    "           'Actor_1_before', 'Actor_0_before'}\n",
    "\n",
    "    wanted_dict = {key : [val] for key ,val in movielist.items() if key in want_keys }   \n",
    "    df = pd.DataFrame.from_dict(wanted_dict)\n",
    "\n",
    "    for i in df.columns:\n",
    "#        print(i)\n",
    "        if df[i].isna().any():\n",
    "            df[i][0] = str(0)\n",
    "    \n",
    "    df[\"runtime\"] = df[\"Runtime\"]\n",
    "    df[\"runtime\"] = df[\"runtime\"].str.replace(\"min\",\"\")\n",
    "    df[\"runtime\"] = df[\"runtime\"].astype(\"float\")\n",
    "    df = df.drop([\"Runtime\"],axis= 1)\n",
    "    try:\n",
    "        df[\"budget_in_USD\"] = df[\"budget_in_USD\"].str.replace('$',\"\").str.replace(\",\",\"\")   \n",
    "    except:\n",
    "        pass\n",
    "    df[\"budget_in_USD\"] = df[\"budget_in_USD\"].astype(\"float\")\n",
    "    \n",
    "    try:\n",
    "        df[\"imdbVotes\"] = df[\"imdbVotes\"][0].replace(\",\",\"\")\n",
    "    except:\n",
    "        pass\n",
    "    df[\"imdbVotes\"] = df[\"imdbVotes\"].astype(\"float\")\n",
    "    \n",
    "    \n",
    "    df['release_date_USA'] = df.release_date_USA.str.split(' ',expand=True)[1]\n",
    "    \n",
    "    #df[\"Cmovie_3_before\"] = df[\"Cmovie_3_before\"].astype(\"str\").replace(\"error\",\"0\").astype(\"float\")\n",
    "    #df[\"Cmovie_2_before\"] = df[\"Cmovie_2_before\"].astype(\"str\").replace(\"error\",\"0\").astype(\"float\")\n",
    "    #df[\"Cmovie_1_before\"] = df[\"Cmovie_1_before\"].astype(\"str\").replace(\"error\",\"0\").astype(\"float\")\n",
    "    #df[\"Cmovie_0_before\"] = df[\"Cmovie_0_before\"].astype(\"str\").replace(\"error\",\"0\").astype(\"float\")\n",
    "#    df[\"movie_3_before\"] = df[\"movie_3_before\"].astype(\"str\").replace(\"error\",\"0\").astype(\"float\")\n",
    "    df[\"movie_2_before\"] = df[\"movie_2_before\"].astype(\"str\").replace(\"error\",\"0\").astype(\"float\")\n",
    "    df[\"movie_1_before\"] = df[\"movie_1_before\"].astype(\"str\").replace(\"error\",\"0\").astype(\"float\")\n",
    "    df[\"movie_0_before\"] = df[\"movie_0_before\"].astype(\"str\").replace(\"error\",\"0\").astype(\"float\")\n",
    "#    df[\"Actor_3_before\"] = df[\"Actor_3_before\"].astype(\"str\").replace(\"error\",\"0\").astype(\"float\")\n",
    "    df[\"Actor_2_before\"] = df[\"Actor_2_before\"].astype(\"str\").replace(\"error\",\"0\").astype(\"float\")\n",
    "    df[\"Actor_1_before\"] = df[\"Actor_1_before\"].astype(\"str\").replace(\"error\",\"0\").astype(\"float\")\n",
    "    df[\"Actor_0_before\"] = df[\"Actor_0_before\"].astype(\"str\").replace(\"error\",\"0\").astype(\"float\")\n",
    "    df= df.join(pd.get_dummies(df[\"classification\"]).astype(\"bool\"))\n",
    "    df = df.drop([\"classification\"], axis=1)\n",
    "    \n",
    "    df= df.join(pd.get_dummies(df[\"release_date_USA\"]).astype(\"bool\"))\n",
    "    df = df.drop([\"release_date_USA\"], axis=1)\n",
    "    \n",
    "    \n",
    "    #onhot encoding\n",
    "    \n",
    "    \n",
    "    \n",
    "    model_wanted_keys=[\n",
    "            'runtime', 'budget_in_USD', 'imdbVotes', 'IMDBscore', 'TomatoesScore',\n",
    "           'Metascore', 'Theater_num', 'movie_2_before',\n",
    "           'movie_1_before', 'movie_0_before', 'Actor_2_before',\n",
    "           'Actor_1_before', 'Actor_0_before', 'G', 'NC-17', 'NotRated', 'PG',\n",
    "           'PG-13', 'R', 'TV-14', 'TV-G', 'TV-MA', 'TV-PG', 'TV-Y', 'TV-Y7',\n",
    "           'TV-Y7-FV', 'Unrated', 'Apr', 'Aug', 'Dec', 'Feb', 'Jan', 'Jul', 'Jun',\n",
    "           'Mar', 'May', 'Nov', 'Oct', 'Sep', 'Action', 'Adventure', 'Animation',\n",
    "           'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family',\n",
    "           'Fantasy', 'History', 'Horror', 'Music', 'Musical', 'Mystery',\n",
    "           'Romance', 'Sci-Fi', 'Sport', 'Thriller', 'War', 'Western']\n",
    "    data = [0]*len(model_wanted_keys)\n",
    "    \n",
    "    df_model = pd.DataFrame(data=[data],columns= model_wanted_keys)\n",
    "    df_model.update(df)\n",
    "    \n",
    "    with open('RandomForest.pickle', 'rb') as f:\n",
    "        clf2 = pickle.load(f)\n",
    "        #测试读取后的Model\n",
    "    return clf2.predict(df_model)[0]\n",
    "\n",
    "def predict_loss(m):\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import re\n",
    "    import xgboost as xgb\n",
    "\n",
    "    \n",
    "    wanted_keys={\"Runtime\",\"budget_in_USD\",\"Production\",\"imdbVotes\",\"IMDBscore\",\"TomatoesScore\",\"Metascore\",\"Theater_num\",\n",
    "                 \"movie_2_before\",\"movie_1_before\",\"movie_0_before\",\"Actor_2_before\",\"Actor_1_before\",\"Actor_0_before\",\n",
    "                 \"Genre\",\"Language\",\"Country\",\"classification\"}\n",
    "    \n",
    "    wanted_dict  = {key : [val] for key ,val in m.items() if key in wanted_keys}\n",
    "    df_company = pd.read_csv(\"company_detail.csv\")\n",
    "    company_dict = {}\n",
    "    for i, s in df_company.iterrows():\n",
    "        company_dict[s[\"company\"]] = s[\"avg\"]\n",
    "    key = list(company_dict.keys())\n",
    "    \n",
    "    regex_pat = re.compile(r\"[^a-zA-Z0-9]+\", flags=re.IGNORECASE)\n",
    "    wanted_dict[\"Production\"][0] = re.sub(regex_pat,'', wanted_dict[\"Production\"][0]).lower()\n",
    "    wanted_dict[\"Production\"] = wanted_dict[\"Production\"][0]\n",
    "    for x in key:\n",
    "        if wanted_dict[\"Production\"].find(x) != -1:\n",
    "           wanted_dict[\"Production\"] = company_dict[wanted_dict[\"Production\"]] \n",
    "           break \n",
    "   # print(\"type\",type(wanted_dict[\"Production\"]),type(wanted_dict[\"Production\"]) == 'str',wanted_dict[\"Production\"])\n",
    "    if type(wanted_dict[\"Production\"]) == str:\n",
    "        wanted_dict[\"Production\"]= 200000\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(wanted_dict)        \n",
    "    cleaned = df.Genre.str.split(',', expand=True).stack()\n",
    "    cleaned = cleaned.apply(lambda x:x.replace(\" \",\"\"))\n",
    "    genre_enc = pd.get_dummies(cleaned, prefix='g').groupby(level=0,sort=False).sum()\n",
    "    \n",
    "    cleaned = df.Language.str.split(',', expand=True).stack()\n",
    "    cleaned = cleaned.apply(lambda x:x.replace(\" \",\"\"))\n",
    "    #drop_lang = (cleaned.value_counts()[cleaned.value_counts()<=5]).index.tolist()\n",
    "    #for l in range(len(cleaned)):\n",
    "    #    if cleaned.iloc[l] in drop_lang:\n",
    "    #        cleaned.iloc[l] = \"Other_language\"\n",
    "    language_enc = pd.get_dummies(cleaned, prefix='L').groupby(level=0,sort=False).sum()\n",
    "    \n",
    "    cleaned = df.Country.str.split(',', expand=True).stack()\n",
    "    cleaned = cleaned.apply(lambda x:x.replace(\" \",\"\"))\n",
    "    country_enc = pd.get_dummies(cleaned, prefix='L').groupby(level=0,sort=False).sum()   \n",
    "        \n",
    "    df[\"Runtime\"] = df[\"Runtime\"].str.replace(\"min\",\"\")\n",
    "    try:\n",
    "        df[\"imdbVotes\"]=df[\"imdbVotes\"].str.replace(\",\",\"\")\n",
    "    except:\n",
    "        pass\n",
    "    for e in df.columns:\n",
    "        if \"movie\" or \"Actor\" in e:\n",
    "            df[e] = df[e].replace(\"error\",\"0\")\n",
    "    cla_enc = pd.get_dummies(df[\"classification\"])\n",
    "    df = df.drop([\"classification\",\"Genre\",\"Language\",\"Country\"],axis=1)\n",
    "    \n",
    "    for i in df.columns:\n",
    "        try:\n",
    "            df[i] =pd.to_numeric(df[i], downcast='float')\n",
    "            #df[\"budget_in_USD\"] = np.log(df[\"budget_in_USD\"])\n",
    "        except:\n",
    "            pass\n",
    "                \n",
    "    \n",
    "    #df[\"Production\"] = np.log(df[\"Production\"])   \n",
    "    df[\"Theater_num\"] = np.log(df[\"Theater_num\"]) \n",
    "    df = pd.concat([df.reset_index(drop=True),genre_enc.reset_index(drop=True),\n",
    "                    country_enc.reset_index(drop=True),language_enc.reset_index(drop=True),\n",
    "                    cla_enc.reset_index(drop=True)\n",
    "                    ],\n",
    "                    axis=1) \n",
    "    \n",
    "    \n",
    "    \n",
    "    feature = ['budget_in_USD','Production','imdbVotes','IMDBscore','TomatoesScore','Metascore','Theater_num',\n",
    " 'movie_2_before','movie_1_before','movie_0_before',\n",
    " 'Actor_2_before','Actor_1_before','Actor_0_before','Runtime','g_Action','g_Adventure','g_Animation','g_Biography',\n",
    " 'g_Comedy','g_Crime','g_Drama','g_Family','g_Fantasy','g_History',\n",
    " 'g_Horror','g_Music','g_Musical','g_Mystery','g_Romance','g_Sci-Fi',\n",
    " 'g_Sport','g_Thriller','g_War','g_Western','L_Algeria','L_Angola','L_Argentina','L_Australia',\n",
    " 'L_Austria','L_Belgium','L_BosniaandHerzegovina','L_Botswana','L_Brazil','L_BritishVirginIslands','L_Bulgaria','L_Cambodia',\n",
    " 'L_Canada','L_CaymanIslands','L_Chile','L_China','L_Colombia',\n",
    " 'L_Croatia','L_Cyprus','L_CzechRepublic','L_Denmark','L_Egypt','L_Estonia','L_Finland','L_France','L_Georgia',\n",
    " 'L_Germany','L_Greece','L_HongKong','L_Hungary','L_Iceland','L_India','L_Indonesia','L_Iran',\n",
    " 'L_Ireland','L_IsleOfMan','L_Israel','L_Italy','L_Japan','L_Jordan','L_Kazakhstan','L_Kenya','L_Lebanon','L_Liechtenstein',\n",
    " 'L_Lithuania','L_Luxembourg','L_Malta','L_Mexico','L_Monaco','L_Mongolia','L_Morocco',\n",
    " 'L_Myanmar','L_Nepal','L_Netherlands','L_NewZealand','L_Nigeria','L_Norway','L_Palestine','L_Panama','L_Paraguay','L_Peru',\n",
    " 'L_Philippines','L_Poland','L_Portugal','L_PuertoRico','L_Qatar','L_Romania','L_Russia','L_SaudiArabia','L_Serbia','L_Singapore','L_Slovakia',\n",
    " 'L_Slovenia','L_SouthAfrica','L_SouthKorea','L_Spain','L_Sweden','L_Switzerland','L_Taiwan','L_Thailand',\n",
    " 'L_Tunisia','L_Turkey','L_UK','L_USA','L_Ukraine','L_UnitedArabEmirates','L_Uruguay','L_Venezuela','L_Vietnam','G','NC-17','NotRated','PG',\n",
    " 'PG-13','R','TV-14','TV-MA','TV-PG','Unrated']\n",
    "    \n",
    "    #feature2 = ['IMDBscore','TV-MA','g_Action','L_Canada','L_HongKong','L_Mexico','L_Jordan','L_India','movie_2_before','L_Chile','L_Peru',\n",
    "    # 'g_Crime','g_Comedy','L_Denmark','L_Venezuela','L_Mongolia','L_Portugal','Actor_1_before','g_Music','L_Iran','L_Cyprus','NotRated',\n",
    "    # 'L_BritishVirginIslands','L_CaymanIslands','L_Iceland','L_Kazakhstan','L_Romania','L_Palestine','TomatoesScore','L_Philippines','L_SaudiArabia',\n",
    "    # 'L_Argentina','budget_in_USD','L_Italy','L_Netherlands','L_Spain','L_UK','g_Drama','L_Malta','Unrated','L_Singapore','L_France',\n",
    "    # 'L_Austria','L_Egypt','L_Kenya','runtime','g_Romance','L_Switzerland','L_SouthAfrica','imdbVotes','L_Lithuania','g_Sport',\n",
    "    # 'movie_0_before','TV-14','L_Slovenia','movie_1_before','L_Nigeria','L_PuertoRico','Actor_2_before','L_Japan','L_Indonesia','g_Fantasy',\n",
    "    # 'L_Israel','NC-17','L_Bulgaria','L_Luxembourg','L_Estonia','L_Algeria','g_Musical','L_IsleOfMan','L_Poland','L_Ireland','Actor_0_before',\n",
    "    # 'g_War','L_Paraguay','L_Cambodia','Metascore','L_Monaco','L_Angola','L_Turkey','L_Georgia','L_Serbia','L_Panama','Production','L_Australia',\n",
    "    # 'L_Colombia','g_Adventure','PG','L_Uruguay','PG-13','g_History','L_Morocco','L_Hungary','L_Myanmar','L_Ukraine','G','TV-PG','g_Horror',\n",
    "    # 'L_Brazil','R','L_Vietnam','L_Lebanon','L_Belgium','g_Sci-Fi','L_Botswana','g_Western','L_Tunisia','L_BosniaandHerzegovina','L_Qatar',\n",
    "    # 'g_Thriller','L_Finland','L_Russia','g_Biography','L_SouthKorea','L_Germany','L_Liechtenstein','L_NewZealand','L_Thailand','g_Animation',\n",
    "    # 'L_Croatia','L_Greece','L_Sweden','L_UnitedArabEmirates','L_CzechRepublic','L_USA','g_Mystery','L_Taiwan','L_Nepal','L_Slovakia',\n",
    "    # 'L_Norway','g_Family','Theater_num','L_China']\n",
    "    \n",
    "    data = [0]*len(feature)\n",
    "    df_model = pd.DataFrame(data=[data],columns=feature)\n",
    "    df_model.update(df)\n",
    "#    feature_list = [\"f\"+str(i) for i in range(len(feature))]\n",
    "#    df_model.columns = feature_list\n",
    "    #for f in feature2:\n",
    "    #    if f not in df.columns.tolist():\n",
    "    #        df_append = pd.DataFrame.from_dict({f:[0]})\n",
    "    #        df=pd.concat([df,df_append],axis=1)\n",
    "    #import joblib\n",
    "    #xgb = joblib.load(\"modeltest\")\n",
    "    import pickle\n",
    "    loaded_model = pickle.load(open(\"loss.pickle.dat\", \"rb\"))\n",
    "    y_pred = loaded_model.predict(df_model)\n",
    "    y_pred = np.exp(y_pred)\n",
    "    return y_pred\n",
    "\n",
    "def predict_gain(m):\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import re\n",
    "    import xgboost as xgb\n",
    "\n",
    "    \n",
    "    wanted_keys={\"Runtime\",\"budget_in_USD\",\"Production\",\"imdbVotes\",\"IMDBscore\",\"TomatoesScore\",\"Metascore\",\"Theater_num\",\n",
    "                 \"movie_2_before\",\"movie_1_before\",\"movie_0_before\",\"Actor_2_before\",\"Actor_1_before\",\"Actor_0_before\",\n",
    "                 \"Genre\",\"Language\",\"Country\",\"classification\"}\n",
    "    \n",
    "    wanted_dict  = {key : [val] for key ,val in m.items() if key in wanted_keys}\n",
    "    df_company = pd.read_csv(\"company_detail.csv\")\n",
    "    company_dict = {}\n",
    "    for i, s in df_company.iterrows():\n",
    "        company_dict[s[\"company\"]] = s[\"avg\"]\n",
    "    key = list(company_dict.keys())\n",
    "    \n",
    "    regex_pat = re.compile(r\"[^a-zA-Z0-9]+\", flags=re.IGNORECASE)\n",
    "    wanted_dict[\"Production\"][0] = re.sub(regex_pat,'', wanted_dict[\"Production\"][0]).lower()\n",
    "    wanted_dict[\"Production\"] = wanted_dict[\"Production\"][0]\n",
    "    for x in key:\n",
    "        if wanted_dict[\"Production\"].find(x) != -1:\n",
    "           wanted_dict[\"Production\"] = company_dict[wanted_dict[\"Production\"]] \n",
    "           break \n",
    "    #print(\"type\",type(wanted_dict[\"Production\"]),type(wanted_dict[\"Production\"]) == 'str',wanted_dict[\"Production\"])\n",
    "    if type(wanted_dict[\"Production\"]) == str:\n",
    "        wanted_dict[\"Production\"]= 200000\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(wanted_dict)        \n",
    "    cleaned = df.Genre.str.split(',', expand=True).stack()\n",
    "    cleaned = cleaned.apply(lambda x:x.replace(\" \",\"\"))\n",
    "    genre_enc = pd.get_dummies(cleaned, prefix='g').groupby(level=0,sort=False).sum()\n",
    "    \n",
    "    cleaned = df.Language.str.split(',', expand=True).stack()\n",
    "    cleaned = cleaned.apply(lambda x:x.replace(\" \",\"\"))\n",
    "    #drop_lang = (cleaned.value_counts()[cleaned.value_counts()<=5]).index.tolist()\n",
    "    #for l in range(len(cleaned)):\n",
    "    #    if cleaned.iloc[l] in drop_lang:\n",
    "    #        cleaned.iloc[l] = \"Other_language\"\n",
    "    language_enc = pd.get_dummies(cleaned, prefix='L').groupby(level=0,sort=False).sum()\n",
    "    \n",
    "    cleaned = df.Country.str.split(',', expand=True).stack()\n",
    "    cleaned = cleaned.apply(lambda x:x.replace(\" \",\"\"))\n",
    "    country_enc = pd.get_dummies(cleaned, prefix='L').groupby(level=0,sort=False).sum()   \n",
    "        \n",
    "    df[\"Runtime\"] = df[\"Runtime\"].str.replace(\"min\",\"\")\n",
    "    try:\n",
    "        df[\"imdbVotes\"]=df[\"imdbVotes\"].str.replace(\",\",\"\")\n",
    "    except:\n",
    "        pass\n",
    "    for e in df.columns:\n",
    "        if \"movie\" or \"Actor\" in e:\n",
    "            df[e] = df[e].replace(\"error\",\"0\")\n",
    "    cla_enc = pd.get_dummies(df[\"classification\"])\n",
    "    df = df.drop([\"classification\",\"Genre\",\"Language\",\"Country\"],axis=1)\n",
    "    \n",
    "    for i in df.columns:\n",
    "\n",
    "        try:\n",
    "            df[i] =pd.to_numeric(df[i], downcast='float')\n",
    "            #df[\"budget_in_USD\"] = np.log(df[\"budget_in_USD\"])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    #df[\"Production\"] = np.log(df[\"Production\"])   \n",
    "    df[\"Theater_num\"] = np.log(df[\"Theater_num\"]) \n",
    "    df = pd.concat([df.reset_index(drop=True),genre_enc.reset_index(drop=True),\n",
    "                    country_enc.reset_index(drop=True),language_enc.reset_index(drop=True),\n",
    "                    cla_enc.reset_index(drop=True)\n",
    "                    ],\n",
    "                    axis=1) \n",
    "    \n",
    "    \n",
    "    \n",
    "    feature = ['budget_in_USD', 'Production', 'imdbVotes', 'IMDBscore',\n",
    "       'TomatoesScore', 'Metascore', 'Theater_num', 'movie_2_before',\n",
    "       'movie_1_before', 'movie_0_before', 'Actor_2_before', 'Actor_1_before',\n",
    "       'Actor_0_before', 'Runtime', 'g_Action', 'g_Adventure', 'g_Animation',\n",
    "       'g_Biography', 'g_Comedy', 'g_Crime', 'g_Drama', 'g_Family',\n",
    "       'g_Fantasy', 'g_History', 'g_Horror', 'g_Music', 'g_Musical',\n",
    "       'g_Mystery', 'g_Romance', 'g_Sci-Fi', 'g_Sport', 'g_Thriller', 'g_War',\n",
    "       'g_Western', 'L_Argentina', 'L_Australia', 'L_Austria', 'L_Bahamas',\n",
    "       'L_Belgium', 'L_Brazil', 'L_Bulgaria', 'L_Cambodia', 'L_Canada',\n",
    "       'L_Chile', 'L_China', 'L_Colombia', 'L_CzechRepublic', 'L_Denmark',\n",
    "       'L_DominicanRepublic', 'L_Finland', 'L_France', 'L_Germany', 'L_Greece',\n",
    "       'L_HongKong', 'L_Hungary', 'L_Iceland', 'L_India', 'L_Indonesia',\n",
    "       'L_Iran', 'L_Ireland', 'L_IsleOfMan', 'L_Israel', 'L_Italy', 'L_Japan',\n",
    "       'L_Kenya', 'L_Luxembourg', 'L_Malaysia', 'L_Malta', 'L_Mexico',\n",
    "       'L_Morocco', 'L_Netherlands', 'L_NewZealand', 'L_Norway',\n",
    "       'L_Philippines', 'L_Poland', 'L_Romania', 'L_Russia', 'L_Serbia',\n",
    "       'L_Singapore', 'L_Slovakia', 'L_SouthAfrica', 'L_SouthKorea', 'L_Spain',\n",
    "       'L_Sweden', 'L_Switzerland', 'L_Taiwan', 'L_Thailand', 'L_Turkey',\n",
    "       'L_UK', 'L_USA', 'L_Ukraine', 'L_UnitedArabEmirates', 'G', 'NotRated',\n",
    "       'PG', 'PG-13', 'R', 'Unrated']\n",
    "    \n",
    "    #feature2 = ['IMDBscore','TV-MA','g_Action','L_Canada','L_HongKong','L_Mexico','L_Jordan','L_India','movie_2_before','L_Chile','L_Peru',\n",
    "    # 'g_Crime','g_Comedy','L_Denmark','L_Venezuela','L_Mongolia','L_Portugal','Actor_1_before','g_Music','L_Iran','L_Cyprus','NotRated',\n",
    "    # 'L_BritishVirginIslands','L_CaymanIslands','L_Iceland','L_Kazakhstan','L_Romania','L_Palestine','TomatoesScore','L_Philippines','L_SaudiArabia',\n",
    "    # 'L_Argentina','budget_in_USD','L_Italy','L_Netherlands','L_Spain','L_UK','g_Drama','L_Malta','Unrated','L_Singapore','L_France',\n",
    "    # 'L_Austria','L_Egypt','L_Kenya','runtime','g_Romance','L_Switzerland','L_SouthAfrica','imdbVotes','L_Lithuania','g_Sport',\n",
    "    # 'movie_0_before','TV-14','L_Slovenia','movie_1_before','L_Nigeria','L_PuertoRico','Actor_2_before','L_Japan','L_Indonesia','g_Fantasy',\n",
    "    # 'L_Israel','NC-17','L_Bulgaria','L_Luxembourg','L_Estonia','L_Algeria','g_Musical','L_IsleOfMan','L_Poland','L_Ireland','Actor_0_before',\n",
    "    # 'g_War','L_Paraguay','L_Cambodia','Metascore','L_Monaco','L_Angola','L_Turkey','L_Georgia','L_Serbia','L_Panama','Production','L_Australia',\n",
    "    # 'L_Colombia','g_Adventure','PG','L_Uruguay','PG-13','g_History','L_Morocco','L_Hungary','L_Myanmar','L_Ukraine','G','TV-PG','g_Horror',\n",
    "    # 'L_Brazil','R','L_Vietnam','L_Lebanon','L_Belgium','g_Sci-Fi','L_Botswana','g_Western','L_Tunisia','L_BosniaandHerzegovina','L_Qatar',\n",
    "    # 'g_Thriller','L_Finland','L_Russia','g_Biography','L_SouthKorea','L_Germany','L_Liechtenstein','L_NewZealand','L_Thailand','g_Animation',\n",
    "    # 'L_Croatia','L_Greece','L_Sweden','L_UnitedArabEmirates','L_CzechRepublic','L_USA','g_Mystery','L_Taiwan','L_Nepal','L_Slovakia',\n",
    "    # 'L_Norway','g_Family','Theater_num','L_China']\n",
    "    \n",
    "    data = [0]*len(feature)\n",
    "    df_model = pd.DataFrame(data=[data],columns=feature)\n",
    "    df_model.update(df)\n",
    "#    feature_list = [\"f\"+str(i) for i in range(len(feature))]\n",
    "#    df_model.columns = feature_list\n",
    "    #for f in feature2:\n",
    "    #    if f not in df.columns.tolist():\n",
    "    #        df_append = pd.DataFrame.from_dict({f:[0]})\n",
    "    #        df=pd.concat([df,df_append],axis=1)\n",
    "    #import joblib\n",
    "    #xgb = joblib.load(\"modeltest\")\n",
    "    import pickle\n",
    "    loaded_model = pickle.load(open(\"gain.pickle.dat\", \"rb\"))\n",
    "    y_pred = loaded_model.predict(df_model)\n",
    "    y_pred = np.exp(y_pred)\n",
    "    return y_pred\n",
    "\n",
    "def run_model(t):#主程式\n",
    "    t = trends_for_line(t)\n",
    "    ans = model_yn(t)\n",
    "    if ans:\n",
    "       return(\"您會賺錢\",predict_gain(t))\n",
    "    else:\n",
    "       return(\"您會虧錢\",predict_loss(t))\n",
    "#if __name__ == \"__main__\":\n",
    "#    a,b=run_model(t)\n",
    "#    print(a, b)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#    t={}\n",
    "#    print(model_yn(t))\n",
    "#    if model_yn(t) == 0:\n",
    "#        print(predict_loss(t))\n",
    "#    else:\n",
    "#        print(predict_gain(t))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "建立comfirm template\n",
    "'''\n",
    "from linebot.models import *\n",
    "comfirm_message = TemplateSendMessage(\n",
    "    alt_text='this is a confirm template',\n",
    "        template=ConfirmTemplate(\n",
    "            title='這是ConfirmTemplate',\n",
    "            text='以上是您輸入的訊息，若訊息無誤請按下確認',\n",
    "            actions=[                              \n",
    "                {\n",
    "        \"type\": \"message\",\n",
    "        \"label\": \"是的沒錯\",\n",
    "        \"text\": \"::text::是的沒錯\"\n",
    "      },\n",
    "      {\n",
    "        \"type\": \"message\",\n",
    "        \"label\": \"我想更改\",\n",
    "        \"text\": \"::text::我想要更改\"\n",
    "      }\n",
    "            ]\n",
    "        )\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "建立表單所需要的問題\n",
    "'''\n",
    "from linebot.models import *\n",
    "quation_dict={\n",
    "'q1':TextSendMessage(text=\"1.請告訴我電影名稱\\n Ex: Iron man 3\"),\n",
    "'q2':TextSendMessage(text=\"2.請告訴我電影時間長度\\n Ex:140min\\n若數字為小數請四捨五入\"),\n",
    "'q3':TextSendMessage(text=\"3.請告訴我您的預算?\\n Ex:5000000\\n若數字為小數請四捨五入\"),\n",
    "'q4':TextSendMessage(text=\"4.請告訴我製片商?\\n Ex:20th Century Fox\"),\n",
    "'q5':TextSendMessage(text=\"5.請告訴我imdb的票數?\\n Ex:55\\n若數字為小數請四捨五入\"),\n",
    "'q6':TextSendMessage(text=\"6.請告訴我imdb的分數?\\n Ex:9\\n若數字為小數請四捨五入\"),\n",
    "'q7':TextSendMessage(text=\"7.請告訴我爛番茄的分數?\\n Ex:8\\n若數字為小數請四捨五入\"),\n",
    "'q8':TextSendMessage(text=\"8.請告訴我您會上映的電影院數?\\n Ex:475\\n若數字為小數請四捨五入\"),\n",
    "'q9':TextSendMessage(text=\"9.請告訴我您電影的種類?\\n Ex:Adventure\"),\n",
    "'q10':TextSendMessage(text=\"10.請告訴我電影的語言?\\n Ex:English\"),\n",
    "'q11':TextSendMessage(text=\"11.請告訴我電影製作的國家?\\n Ex:USA\"),\n",
    "'q12':TextSendMessage(text=\"12.請告訴我電影的分級?\\n Ex:PG-13\"),\n",
    "'q13':TextSendMessage(text=\"13.請告訴我電影的Metascore?\\n Ex:5\\n若數字為小數請四捨五入\"),\n",
    "'q14':TextSendMessage(text=\"14.請告訴我電影的預計上印日期?\\n Ex:01 JUN 2019\"),\n",
    "'q15':TextSendMessage(text=\"15.請告訴我主要三個演員?\\n EX:Robert Downey Jr,Chris Evans,Scarlett Johansson\")}\n",
    "remind = TextSendMessage(texr=\"不好意思，請您依照提示格式輸入\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#設定預測方面所需要的功能\n",
    "import re\n",
    "from linebot.models import *\n",
    "class_ =[\"G\",\"PG\",\"PG13\",\"R\",\"NC17\"]\n",
    "number_re = re.compile(\"\\D\")\n",
    "character_re = re.compile(\"\\d\")\n",
    "min_re = re.compile('min')\n",
    "count = 0\n",
    "model_dict={}\n",
    "quation_list = [\"movie_name\",\"Runtime\",\"budget_in_USD\",\"Production\",\"imdbVotes\",\"IMDBscore\",\"TomatoesScore\",\n",
    "                \"Theater_num\",\"Genre\",\"Language\",\"Country\",\"classification\",\"Metascore\",\"Released\",\"actor\"]\n",
    "model_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = {}\n",
    "def predict_text(event):\n",
    "    text = event.message.text\n",
    "    #選擇進入後，進行richmenu的轉換，並且傳送第一個問題\n",
    "    if text == \"::text:: 我要精準預測\":\n",
    "        # 取出用戶id，設定Line的遠端位置\n",
    "        userMenuEndpoint='https://api.line.me/v2/bot/user/%s/richmenu' % (secretFileContentJson[\"self_user_id\"])\n",
    "        # 設定消息的基本安全憑證\n",
    "        userMenuRequestHeader={'Authorization':'Bearer %s' % secretFileContentJson[\"channel_access_token\"]}\n",
    "        # 發送消息告知已經解除\n",
    "        lineUnregisterUserMenuResponse=requests.delete(userMenuEndpoint,headers=userMenuRequestHeader)\n",
    "        # 取得菜單id\n",
    "        linkRichMenuId2=secretFileContentJson.get(\"rich_menu_id2\")\n",
    "        # 將菜單id與用戶id組合成遠端位置\n",
    "        linkMenuEndpoint2='https://api.line.me/v2/bot/user/%s/richmenu/%s' % (secretFileContentJson[\"self_user_id\"], linkRichMenuId2)\n",
    "        # 設定消息基本安全憑證\n",
    "        linkMenuRequestHeader2={'Content-Type':'image/jpeg','Authorization':'Bearer %s' % secretFileContentJson[\"channel_access_token\"]}\n",
    "        # 發送消息\n",
    "        lineLinkMenuResponse2=requests.post(linkMenuEndpoint2,headers=linkMenuRequestHeader2)\n",
    "        #並且發送問文字訊息\n",
    "        reply_text = \"您好，歡迎使用我們的電影預測系統，以下是我們預測所需要的變數，請您幫忙依照例子回答!! \\n並請在所有回答中加上'::q+題目號::'，以方便我們確認是哪一題喔\"\n",
    "        message_first_predict_list = [TextSendMessage(reply_text),quation_dict.get('q1')]\n",
    "        line_bot_api.reply_message(\n",
    "            event.reply_token,\n",
    "            message_first_predict_list\n",
    "        )\n",
    "    elif (text.find('::q')!= -1):\n",
    "        text_split = text.split(\"::\")\n",
    "        number = int(text.split(\"::\")[1].replace('q','q_').split(\"_\")[1])\n",
    "        answer = text_split[2]\n",
    "        if number in [3,5,8]:\n",
    "            if number_re.search(answer.replace(\" \",\"\")) == None:\n",
    "                sto_num = number-1\n",
    "                storage[quation_list[sto_num]]=answer\n",
    "                next_num = number+1\n",
    "                quation_num = 'q'+str(next_num)\n",
    "                line_bot_api.reply_message(event.reply_token,quation_dict.get(quation_num))\n",
    "            else:\n",
    "                line_bot_api.reply_message(\n",
    "                    event.reply_token,\n",
    "                    quation_dict.get(text_split[1]))\n",
    "        elif number == 2:\n",
    "            if min_re.search(answer.replace(\" \",\"\")) != None:\n",
    "                sto_num = number-1\n",
    "                storage[quation_list[sto_num]]=answer\n",
    "                next_num = number+1\n",
    "                quation_num = 'q'+str(next_num)\n",
    "                line_bot_api.reply_message(event.reply_token,quation_dict.get(quation_num))\n",
    "            else:\n",
    "                line_bot_api.reply_message(\n",
    "                    event.reply_token,\n",
    "                    quation_dict.get(text_split[1]))\n",
    "        elif number in [6,7,13]:\n",
    "            if number_re.search(answer.replace(\" \",\"\")) == None:\n",
    "                sto_num = number-1\n",
    "                storage[quation_list[sto_num]]=round(float(answer.replace(\" \",\"\"))/10,1)\n",
    "                next_num = number+1\n",
    "                quation_num = 'q'+str(next_num)\n",
    "                line_bot_api.reply_message(event.reply_token,quation_dict.get(quation_num))\n",
    "            else:\n",
    "                line_bot_api.reply_message(\n",
    "                    event.reply_token,\n",
    "                    quation_dict.get(text_split[1]))\n",
    "            \n",
    "        elif number in [9,10,11]:\n",
    "            if character_re.search(answer) == None:\n",
    "                sto_num = number-1\n",
    "                storage[quation_list[sto_num]]=answer\n",
    "                next_num = number+1\n",
    "                quation_num = 'q'+str(next_num)\n",
    "                line_bot_api.reply_message(event.reply_token,quation_dict.get(quation_num))\n",
    "            else:\n",
    "                line_bot_api.reply_message(\n",
    "                    event.reply_token,\n",
    "                    quation_dict.get(text_split[1]))\n",
    "        elif number ==12:\n",
    "            if answer in class_:\n",
    "                sto_num = number-1\n",
    "                storage[quation_list[sto_num]]=answer\n",
    "                next_num = number+1\n",
    "                quation_num = 'q'+str(next_num)\n",
    "                line_bot_api.reply_message(event.reply_token,quation_dict.get(quation_num))\n",
    "            else:\n",
    "                line_bot_api.reply_message(\n",
    "                    event.reply_token,\n",
    "                    quation_dict.get(text_split[1]))\n",
    "        elif number in [1,4,14]:\n",
    "            sto_num = number-1\n",
    "            storage[quation_list[sto_num]]=answer\n",
    "            next_num = number+1\n",
    "            quation_num = 'q'+str(next_num)\n",
    "            line_bot_api.reply_message(event.reply_token,quation_dict.get(quation_num))\n",
    "        elif number ==15:\n",
    "            sto_num = number-1\n",
    "            storage[quation_list[sto_num]]=answer\n",
    "            print(storage)\n",
    "            \n",
    "            message_final_list = [TextSendMessage(text='以下是您填寫的資訊，若確認無誤請點下幫確認鍵'),\n",
    "                                  TextSendMessage(text=str(storage)),\n",
    "                                  comfirm_message]\n",
    "            line_bot_api.reply_message(event.reply_token,message_final_list)\n",
    "            \n",
    "    elif text == '::text::是的沒錯':\n",
    "        a,b =run_model(storage)\n",
    "        print(type(a),type(b))\n",
    "        text_final = a + '您的票房預估:'+str(b[0])\n",
    "        if a == '您會虧錢':\n",
    "            line_bot_api.reply_message(event.reply_token,TextSendMessage(text=text_final))\n",
    "        else:\n",
    "            line_bot_api.reply_message(event.reply_token,TextSendMessage(text=text_final))\n",
    "            \n",
    "    elif text ==':text::我想要更改':\n",
    "        line_bot_api.reply_message(event.reply_token,quation_dict.get('q1'))\n",
    "        \n",
    "            \n",
    "            \n",
    "                \n",
    "        \n",
    "    # 設定richmenu的功能\n",
    "    elif text ==\"::text:: 我填錯了想重來~\":\n",
    "        line_bot_api.reply_message(\n",
    "        event.reply_token,\n",
    "        quation_dict.get('q1'))\n",
    "    # 設定錯誤回答的答案\n",
    "    else:\n",
    "        line_bot_api.reply_message(\n",
    "        event.reply_token,\n",
    "        TextSendMessage(text=\"請點擊下方表單功能\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "用戶按下電影預測時進行用戶圖文表單切換\n",
    "並且開始問卷\n",
    "先寫出計數器\n",
    "創建字典\n",
    "'''\n",
    "@handler.add(MessageEvent, message=TextMessage)\n",
    "def handle_message(event):    \n",
    "    print(event)\n",
    "    predict_text(event)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n",
      "172.17.0.3 - - [16/Jul/2019 14:15:58] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": {\"id\": \"10224030046236\", \"text\": \"::q1::herry\", \"type\": \"text\"}, \"replyToken\": \"aa62e1874fe447d98ab440776750b5ed\", \"source\": {\"type\": \"user\", \"userId\": \"Uf9843444c3b5cebc5d5dd94df2fef2c9\"}, \"timestamp\": 1563286556782, \"type\": \"message\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.17.0.3 - - [16/Jul/2019 14:16:03] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": {\"id\": \"10224030547790\", \"text\": \"::q2::101min\", \"type\": \"text\"}, \"replyToken\": \"3fe9718a6c944a8ca5e6c5171c67b509\", \"source\": {\"type\": \"user\", \"userId\": \"Uf9843444c3b5cebc5d5dd94df2fef2c9\"}, \"timestamp\": 1563286562280, \"type\": \"message\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.17.0.3 - - [16/Jul/2019 14:16:15] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": {\"id\": \"10224031600652\", \"text\": \"::q3::1400000\", \"type\": \"text\"}, \"replyToken\": \"b7201e98b34742c8ac2263485b5b8f43\", \"source\": {\"type\": \"user\", \"userId\": \"Uf9843444c3b5cebc5d5dd94df2fef2c9\"}, \"timestamp\": 1563286573592, \"type\": \"message\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.17.0.3 - - [16/Jul/2019 14:16:18] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": {\"id\": \"10224031930314\", \"text\": \"::q4::aaa\", \"type\": \"text\"}, \"replyToken\": \"c921e246e0964f788222e205510012a4\", \"source\": {\"type\": \"user\", \"userId\": \"Uf9843444c3b5cebc5d5dd94df2fef2c9\"}, \"timestamp\": 1563286577108, \"type\": \"message\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.17.0.3 - - [16/Jul/2019 14:16:23] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": {\"id\": \"10224032347245\", \"text\": \"::q6::5\", \"type\": \"text\"}, \"replyToken\": \"bdb244e53fbd46ac9a7b478ed84adc2a\", \"source\": {\"type\": \"user\", \"userId\": \"Uf9843444c3b5cebc5d5dd94df2fef2c9\"}, \"timestamp\": 1563286581734, \"type\": \"message\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.17.0.3 - - [16/Jul/2019 14:16:29] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": {\"id\": \"10224032905005\", \"text\": \"::q5::100\", \"type\": \"text\"}, \"replyToken\": \"c9299d994f1f4fe6bae5d87ad429df18\", \"source\": {\"type\": \"user\", \"userId\": \"Uf9843444c3b5cebc5d5dd94df2fef2c9\"}, \"timestamp\": 1563286587766, \"type\": \"message\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.17.0.3 - - [16/Jul/2019 14:16:35] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": {\"id\": \"10224033477965\", \"text\": \"::q7::6\", \"type\": \"text\"}, \"replyToken\": \"c6fd86f11c234a03b646e4784477e807\", \"source\": {\"type\": \"user\", \"userId\": \"Uf9843444c3b5cebc5d5dd94df2fef2c9\"}, \"timestamp\": 1563286593907, \"type\": \"message\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.17.0.3 - - [16/Jul/2019 14:16:39] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": {\"id\": \"10224033821405\", \"text\": \"::q8::1000\", \"type\": \"text\"}, \"replyToken\": \"feffe082b6a14d1791f1c42a59cdfe6b\", \"source\": {\"type\": \"user\", \"userId\": \"Uf9843444c3b5cebc5d5dd94df2fef2c9\"}, \"timestamp\": 1563286597649, \"type\": \"message\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.17.0.3 - - [16/Jul/2019 14:16:43] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": {\"id\": \"10224034232875\", \"text\": \"::q9::Action\", \"type\": \"text\"}, \"replyToken\": \"bed838aee50741d3abc1c25afcc8054a\", \"source\": {\"type\": \"user\", \"userId\": \"Uf9843444c3b5cebc5d5dd94df2fef2c9\"}, \"timestamp\": 1563286602046, \"type\": \"message\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.17.0.3 - - [16/Jul/2019 14:16:48] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": {\"id\": \"10224034686396\", \"text\": \"::q10::English\", \"type\": \"text\"}, \"replyToken\": \"5f5d26bfd1a54d95a4b16e0b3b033ac9\", \"source\": {\"type\": \"user\", \"userId\": \"Uf9843444c3b5cebc5d5dd94df2fef2c9\"}, \"timestamp\": 1563286607078, \"type\": \"message\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.17.0.3 - - [16/Jul/2019 14:16:53] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": {\"id\": \"10224035124928\", \"text\": \"::q11::USA\", \"type\": \"text\"}, \"replyToken\": \"0b6f3a72dd8840e887e8723ea8cbf1a5\", \"source\": {\"type\": \"user\", \"userId\": \"Uf9843444c3b5cebc5d5dd94df2fef2c9\"}, \"timestamp\": 1563286611871, \"type\": \"message\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.17.0.3 - - [16/Jul/2019 14:16:57] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": {\"id\": \"10224035471053\", \"text\": \"::q12::R\", \"type\": \"text\"}, \"replyToken\": \"bf12b840db9e4a8eb5e6db9f5b1d28f3\", \"source\": {\"type\": \"user\", \"userId\": \"Uf9843444c3b5cebc5d5dd94df2fef2c9\"}, \"timestamp\": 1563286615640, \"type\": \"message\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.17.0.3 - - [16/Jul/2019 14:17:00] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": {\"id\": \"10224035813600\", \"text\": \"::q13::5\", \"type\": \"text\"}, \"replyToken\": \"22a3d5da680c4900bf8e768ac62ce209\", \"source\": {\"type\": \"user\", \"userId\": \"Uf9843444c3b5cebc5d5dd94df2fef2c9\"}, \"timestamp\": 1563286619394, \"type\": \"message\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.17.0.3 - - [16/Jul/2019 14:17:06] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": {\"id\": \"10224036324860\", \"text\": \"::q14::27 Feb 2019\", \"type\": \"text\"}, \"replyToken\": \"c8baa903e2a24739a091c13cef34fb06\", \"source\": {\"type\": \"user\", \"userId\": \"Uf9843444c3b5cebc5d5dd94df2fef2c9\"}, \"timestamp\": 1563286625110, \"type\": \"message\"}\n",
      "{\"message\": {\"id\": \"10224036654266\", \"text\": \"::q15::Johney\", \"type\": \"text\"}, \"replyToken\": \"dcaaf03f95e64a67980b5d48c845bf33\", \"source\": {\"type\": \"user\", \"userId\": \"Uf9843444c3b5cebc5d5dd94df2fef2c9\"}, \"timestamp\": 1563286628754, \"type\": \"message\"}\n",
      "{'movie_name': 'herry', 'Runtime': '101min', 'budget_in_USD': '1400000', 'Production': 'aaa', 'IMDBscore': 0.5, 'imdbVotes': '100', 'TomatoesScore': 0.6, 'Theater_num': '1000', 'Genre': 'Action', 'Language': 'English', 'Country': 'USA', 'classification': 'R', 'Metascore': 0.5, 'Released': '27 Feb 2019', 'actor': 'Johney'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.17.0.3 - - [16/Jul/2019 14:17:10] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": {\"id\": \"10224037492565\", \"text\": \"::text::\\u662f\\u7684\\u6c92\\u932f\", \"type\": \"text\"}, \"replyToken\": \"77ae54b443b74ef58ab0447c2f6f29e5\", \"source\": {\"type\": \"user\", \"userId\": \"Uf9843444c3b5cebc5d5dd94df2fef2c9\"}, \"timestamp\": 1563286638194, \"type\": \"message\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.20.3 when using version 0.21.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.20.3 when using version 0.21.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "172.17.0.3 - - [16/Jul/2019 14:17:42] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:17:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "<class 'str'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "執行此句，啟動Server，觀察後，按左上方塊，停用Server\n",
    "\n",
    "'''\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
